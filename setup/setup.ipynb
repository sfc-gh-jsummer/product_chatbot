{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, Dict, Optional\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session(config: Union[str, Dict[str, str]],\n",
    "                   connection: Optional[str] = None) -> Session:\n",
    "\n",
    "    \"\"\"Establishes a snowpark connection to snowflake.\n",
    "\n",
    "    Uses connection parameters, passed via .json config file or directly in python dict.\n",
    "\n",
    "    Args:\n",
    "        config (str/Dict) : (Relative/absolute) path to .json config file or\n",
    "                            dict of connection(s) params.\n",
    "        connection (str) : Specific key of preferred connection parameters held in config.\n",
    "                           Defaults to None, meaning a single set of connection parameters\n",
    "                           should be passed.\n",
    "\n",
    "    Returns\n",
    "        snowflake.snowpark.Session\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    import json\n",
    "\n",
    "    if isinstance(config, str):  # File path passed\n",
    "        with open(config) as f:\n",
    "            connection_parameters = json.load(f)\n",
    "    else:  # Dict of connections passed\n",
    "        connection_parameters = config\n",
    "    if connection:  # A specific key passed specifying connection params in config\n",
    "        session = Session.builder.configs(connection_parameters[connection]).create()\n",
    "    else:\n",
    "        session = Session.builder.configs(connection_parameters).create()\n",
    "    return session\n",
    "\n",
    "session = create_session(config = '/Users/jsummer/.snowpark/config.json', # Set to path to .json credentials similar to snowSQL\n",
    "                         connection = 'SCS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('setup.yaml', 'r') as yaml_file:\n",
    "    account_specs = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set account-based constants\n",
    "HUGGINGFACE_TOKEN = account_specs['HUGGINGFACE_TOKEN']\n",
    "FILES_STAGE = account_specs['FILES_STAGE']\n",
    "SPEC_STAGE = account_specs['SPEC_STAGE']\n",
    "UDF_STAGE = account_specs['UDF_STAGE']\n",
    "DATA_STAGE = account_specs['DATA_STAGE']\n",
    "IMAGE_REPOSITORY = account_specs['IMAGE_REPOSITORY']\n",
    "SNOW_ROLE =  account_specs['SNOW_ROLE']\n",
    "SNOW_DATABASE = account_specs['SNOW_DATABASE']\n",
    "SNOW_SCHEMA = account_specs['SNOW_SCHEMA']\n",
    "SNOW_WAREHOUSE = account_specs['SNOW_WAREHOUSE']\n",
    "CHAT_LOG_TABLE = account_specs['CHAT_LOG_TABLE']\n",
    "SOURCE_TABLE_ID = account_specs['SOURCE_TABLE_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_role(SNOW_ROLE)\n",
    "session.use_database(SNOW_DATABASE)\n",
    "session.use_schema(SNOW_SCHEMA)\n",
    "session.use_warehouse(SNOW_WAREHOUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(f\"CREATE IMAGE REPOSITORY IF NOT EXISTS {IMAGE_REPOSITORY}\").collect()\n",
    "session.sql(f\"CREATE STAGE IF NOT EXISTS {FILES_STAGE} DIRECTORY = ( ENABLE = true ) encryption = (type = 'SNOWFLAKE_SSE')\").collect()\n",
    "session.sql(f\"CREATE STAGE IF NOT EXISTS {DATA_STAGE} DIRECTORY = ( ENABLE = true ) encryption = (type = 'SNOWFLAKE_SSE')\").collect()\n",
    "session.sql(f\"CREATE STAGE IF NOT EXISTS {SPEC_STAGE}\").collect()\n",
    "session.sql(f\"CREATE STAGE IF NOT EXISTS {UDF_STAGE}\").collect()\n",
    "session.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {CHAT_LOG_TABLE}\n",
    "                (RUN_ID string,\n",
    "                TIMESTAMP timestamp_ltz,\n",
    "                USER_PROMPT string,\n",
    "                ASSISTANT_RESPONSE string,\n",
    "                SOURCE_DOCUMENTS variant)\"\"\").collect()\n",
    "\n",
    "REPOSITORY_URL = session.sql(f\"SHOW IMAGE REPOSITORIES LIKE '{IMAGE_REPOSITORY}'\").collect()[0].repository_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_spec(filepath):\n",
    "    # Load the YAML data into a Python dictionary\n",
    "    with open(filepath, 'r') as yaml_file:\n",
    "        print(f\"Updating {filepath}\")\n",
    "        spec = yaml.safe_load(yaml_file)\n",
    "        spec['spec']['containers'][0]['image'] = f\"{REPOSITORY_URL}/{spec['spec']['containers'][0]['name']}\"\n",
    "\n",
    "        for k in spec['spec']['containers'][0]['env']:\n",
    "            if k == \"HUGGINGFACE_TOKEN\":\n",
    "                spec['spec']['containers'][0]['env'][k] = HUGGINGFACE_TOKEN\n",
    "            if k == \"SNOW_ROLE\":\n",
    "                spec['spec']['containers'][0]['env'][k] = SNOW_ROLE\n",
    "            if k == \"SNOW_DATABASE\":\n",
    "                spec['spec']['containers'][0]['env'][k] = SNOW_DATABASE\n",
    "            if k == \"SNOW_SCHEMA\":\n",
    "                spec['spec']['containers'][0]['env'][k] = SNOW_SCHEMA\n",
    "            if k == \"SNOW_WAREHOUSE\":\n",
    "                spec['spec']['containers'][0]['env'][k] = SNOW_WAREHOUSE\n",
    "            if k == \"PRODUCT_ID\":\n",
    "                spec['spec']['containers'][0]['env'][k] = SOURCE_TABLE_ID\n",
    "        \n",
    "        for i, k in enumerate(spec['spec']['volumes']):\n",
    "            if k['name'].lower() == 'stage':\n",
    "                spec['spec']['volumes'][i]['source'] = f'@{FILES_STAGE}'\n",
    "            if k['name'].lower() == 'data':\n",
    "                spec['spec']['volumes'][i]['source'] = f'@{DATA_STAGE}'\n",
    "    with open(filepath, 'w') as yaml_file:\n",
    "        yaml.dump(spec, yaml_file, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating ../app/chat.yaml\n",
      "Updating ../vllm/vllm.yaml\n",
      "Updating ../weaviate/text2vec.yaml\n",
      "Updating ../weaviate/weaviate.yaml\n",
      "Updating ../weaviate/jupyter.yaml\n"
     ]
    }
   ],
   "source": [
    "ignore_files = ['setup.yaml', 'system_prompt.yaml', 'repo_meta.yaml'] # These are non-spec yamls to ignore\n",
    "for root, dirs, files in os.walk(\"../\"):\n",
    "    for x in files:\n",
    "        if x.endswith('.yaml') and not x.endswith(tuple(ignore_files)):\n",
    "            update_spec(f'{root}/{x}')\n",
    "            session.file.put(f'{root}/{x}',\n",
    "                             f'@{SPEC_STAGE}',\n",
    "                             auto_compress = False,\n",
    "                             overwrite = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airmiles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
